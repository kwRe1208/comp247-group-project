{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Project - KSI data - Classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Target Column***\n",
    "ACCLASS<br>\n",
    "Required to transform into binary (0, 1):<br>\n",
    "'Fatal' --> 1, <br>\n",
    "'Non-Fatal Injury' --> 0, <br>\n",
    "'Property Damage Only' --> 0, <br>\n",
    "***5 nan value from this column, we can consider to drop them***\n",
    "\n",
    "\n",
    "\n",
    "below columns need to fill values:\n",
    "'PEDESTRIAN', 'CYCLIST', 'AUTOMOBILE', 'MOTORCYCLE', 'TRUCK',\n",
    "'TRSN_CITY_VEH', 'EMERG_VEH', 'PASSENGER', 'SPEEDING', 'AG_DRIV',\n",
    "'REDLIGHT', 'ALCOHOL', 'DISABILITY'\n",
    "fill Nan as No, and transform to 0, 1\n",
    "(Default they are Yes, Nan values)\n",
    "ROAD_CLASS fill most freq value\n",
    "DISTRICT fill most freq value\n",
    "\n",
    "Questionable column:\n",
    "CYCCOND: multi categories, fill Nan as most freq value??\n",
    "\n",
    "\n",
    "From the dataset, below columns are unnecessary:\n",
    "ObjectId, HEIGHBOURHOOD_158, HEIGHBOURHOOD_140, CYCLISTYPE(too much categories and too much Nan value),<br>\n",
    "PEDCOND(too much categories and too much Nan value), PEDACT(too much categories and too much Nan value),<br>\n",
    "PEDTYPE (too much categories and too much Nan value), DRICOND ('other' included, means it is not a accuracy value), DRIVACT ('other' included, means it is not a accuracy value), MANOEUVER('other' included, means it is not a accuracy value)<br>\n",
    "FATAL_NO, INVTYPE, DATE, YEAR, ACCNUM, INDEX_, STREET1, STREET2, OFFSET, X, Y,INJURY\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r'dataset\\KSI.csv'\n",
    "\n",
    "df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>INDEX_</th>\n",
       "      <th>ACCNUM</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>STREET1</th>\n",
       "      <th>STREET2</th>\n",
       "      <th>OFFSET</th>\n",
       "      <th>...</th>\n",
       "      <th>AG_DRIV</th>\n",
       "      <th>REDLIGHT</th>\n",
       "      <th>ALCOHOL</th>\n",
       "      <th>DISABILITY</th>\n",
       "      <th>HOOD_158</th>\n",
       "      <th>NEIGHBOURHOOD_158</th>\n",
       "      <th>HOOD_140</th>\n",
       "      <th>NEIGHBOURHOOD_140</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>ObjectId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8.844611e+06</td>\n",
       "      <td>5.412414e+06</td>\n",
       "      <td>3387730</td>\n",
       "      <td>892658.0</td>\n",
       "      <td>2006</td>\n",
       "      <td>2006/03/11 05:00:00+00</td>\n",
       "      <td>852</td>\n",
       "      <td>BLOOR ST W</td>\n",
       "      <td>DUNDAS ST W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88</td>\n",
       "      <td>High Park North</td>\n",
       "      <td>88</td>\n",
       "      <td>High Park North (88)</td>\n",
       "      <td>D11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-8.844611e+06</td>\n",
       "      <td>5.412414e+06</td>\n",
       "      <td>3387731</td>\n",
       "      <td>892658.0</td>\n",
       "      <td>2006</td>\n",
       "      <td>2006/03/11 05:00:00+00</td>\n",
       "      <td>852</td>\n",
       "      <td>BLOOR ST W</td>\n",
       "      <td>DUNDAS ST W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88</td>\n",
       "      <td>High Park North</td>\n",
       "      <td>88</td>\n",
       "      <td>High Park North (88)</td>\n",
       "      <td>D11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.816480e+06</td>\n",
       "      <td>5.434843e+06</td>\n",
       "      <td>3388101</td>\n",
       "      <td>892810.0</td>\n",
       "      <td>2006</td>\n",
       "      <td>2006/03/11 05:00:00+00</td>\n",
       "      <td>915</td>\n",
       "      <td>MORNINGSIDE AVE</td>\n",
       "      <td>SHEPPARD AVE E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146</td>\n",
       "      <td>Malvern East</td>\n",
       "      <td>132</td>\n",
       "      <td>Malvern (132)</td>\n",
       "      <td>D42</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-8.829728e+06</td>\n",
       "      <td>5.419071e+06</td>\n",
       "      <td>3389067</td>\n",
       "      <td>893184.0</td>\n",
       "      <td>2006</td>\n",
       "      <td>2006/01/01 05:00:00+00</td>\n",
       "      <td>236</td>\n",
       "      <td>WOODBINE AVE</td>\n",
       "      <td>O CONNOR DR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>Woodbine-Lumsden</td>\n",
       "      <td>60</td>\n",
       "      <td>Woodbine-Lumsden (60)</td>\n",
       "      <td>D55</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-8.816480e+06</td>\n",
       "      <td>5.434843e+06</td>\n",
       "      <td>3388102</td>\n",
       "      <td>892810.0</td>\n",
       "      <td>2006</td>\n",
       "      <td>2006/03/11 05:00:00+00</td>\n",
       "      <td>915</td>\n",
       "      <td>MORNINGSIDE AVE</td>\n",
       "      <td>SHEPPARD AVE E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146</td>\n",
       "      <td>Malvern East</td>\n",
       "      <td>132</td>\n",
       "      <td>Malvern (132)</td>\n",
       "      <td>D42</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              X             Y   INDEX_    ACCNUM  YEAR  \\\n",
       "0 -8.844611e+06  5.412414e+06  3387730  892658.0  2006   \n",
       "1 -8.844611e+06  5.412414e+06  3387731  892658.0  2006   \n",
       "2 -8.816480e+06  5.434843e+06  3388101  892810.0  2006   \n",
       "3 -8.829728e+06  5.419071e+06  3389067  893184.0  2006   \n",
       "4 -8.816480e+06  5.434843e+06  3388102  892810.0  2006   \n",
       "\n",
       "                     DATE  TIME          STREET1         STREET2 OFFSET  ...  \\\n",
       "0  2006/03/11 05:00:00+00   852       BLOOR ST W     DUNDAS ST W    NaN  ...   \n",
       "1  2006/03/11 05:00:00+00   852       BLOOR ST W     DUNDAS ST W    NaN  ...   \n",
       "2  2006/03/11 05:00:00+00   915  MORNINGSIDE AVE  SHEPPARD AVE E    NaN  ...   \n",
       "3  2006/01/01 05:00:00+00   236     WOODBINE AVE     O CONNOR DR    NaN  ...   \n",
       "4  2006/03/11 05:00:00+00   915  MORNINGSIDE AVE  SHEPPARD AVE E    NaN  ...   \n",
       "\n",
       "  AG_DRIV REDLIGHT  ALCOHOL  DISABILITY  HOOD_158 NEIGHBOURHOOD_158 HOOD_140  \\\n",
       "0     Yes      NaN      NaN         NaN        88   High Park North       88   \n",
       "1     Yes      NaN      NaN         NaN        88   High Park North       88   \n",
       "2     Yes      Yes      NaN         NaN       146      Malvern East      132   \n",
       "3     Yes      NaN      Yes         NaN        60  Woodbine-Lumsden       60   \n",
       "4     Yes      Yes      NaN         NaN       146      Malvern East      132   \n",
       "\n",
       "       NEIGHBOURHOOD_140 DIVISION ObjectId  \n",
       "0   High Park North (88)      D11        1  \n",
       "1   High Park North (88)      D11        2  \n",
       "2          Malvern (132)      D42        3  \n",
       "3  Woodbine-Lumsden (60)      D55        4  \n",
       "4          Malvern (132)      D42        5  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18194 entries, 0 to 18193\n",
      "Data columns (total 57 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   X                  18194 non-null  float64\n",
      " 1   Y                  18194 non-null  float64\n",
      " 2   INDEX_             18194 non-null  int64  \n",
      " 3   ACCNUM             13264 non-null  float64\n",
      " 4   YEAR               18194 non-null  int64  \n",
      " 5   DATE               18194 non-null  object \n",
      " 6   TIME               18194 non-null  int64  \n",
      " 7   STREET1            18194 non-null  object \n",
      " 8   STREET2            16510 non-null  object \n",
      " 9   OFFSET             3402 non-null   object \n",
      " 10  ROAD_CLASS         17818 non-null  object \n",
      " 11  DISTRICT           18089 non-null  object \n",
      " 12  WARDNUM            17332 non-null  float64\n",
      " 13  LATITUDE           18194 non-null  float64\n",
      " 14  LONGITUDE          18194 non-null  float64\n",
      " 15  LOCCOORD           18099 non-null  object \n",
      " 16  ACCLOC             12744 non-null  object \n",
      " 17  TRAFFCTL           18160 non-null  object \n",
      " 18  VISIBILITY         18174 non-null  object \n",
      " 19  LIGHT              18194 non-null  object \n",
      " 20  RDSFCOND           18169 non-null  object \n",
      " 21  ACCLASS            18189 non-null  object \n",
      " 22  IMPACTYPE          18190 non-null  object \n",
      " 23  INVTYPE            18178 non-null  object \n",
      " 24  INVAGE             18194 non-null  object \n",
      " 25  INJURY             9627 non-null   object \n",
      " 26  FATAL_NO           827 non-null    float64\n",
      " 27  INITDIR            13142 non-null  object \n",
      " 28  VEHTYPE            14966 non-null  object \n",
      " 29  MANOEUVER          10534 non-null  object \n",
      " 30  DRIVACT            9243 non-null   object \n",
      " 31  DRIVCOND           9240 non-null   object \n",
      " 32  PEDTYPE            3060 non-null   object \n",
      " 33  PEDACT             3082 non-null   object \n",
      " 34  PEDCOND            3084 non-null   object \n",
      " 35  CYCLISTYPE         774 non-null    object \n",
      " 36  CYCACT             766 non-null    object \n",
      " 37  CYCCOND            765 non-null    object \n",
      " 38  PEDESTRIAN         7354 non-null   object \n",
      " 39  CYCLIST            1906 non-null   object \n",
      " 40  AUTOMOBILE         16550 non-null  object \n",
      " 41  MOTORCYCLE         1587 non-null   object \n",
      " 42  TRUCK              1122 non-null   object \n",
      " 43  TRSN_CITY_VEH      1110 non-null   object \n",
      " 44  EMERG_VEH          43 non-null     object \n",
      " 45  PASSENGER          6906 non-null   object \n",
      " 46  SPEEDING           2575 non-null   object \n",
      " 47  AG_DRIV            9460 non-null   object \n",
      " 48  REDLIGHT           1520 non-null   object \n",
      " 49  ALCOHOL            788 non-null    object \n",
      " 50  DISABILITY         486 non-null    object \n",
      " 51  HOOD_158           18194 non-null  object \n",
      " 52  NEIGHBOURHOOD_158  18194 non-null  object \n",
      " 53  HOOD_140           18194 non-null  object \n",
      " 54  NEIGHBOURHOOD_140  18194 non-null  object \n",
      " 55  DIVISION           18194 non-null  object \n",
      " 56  ObjectId           18194 non-null  int64  \n",
      "dtypes: float64(7), int64(4), object(46)\n",
      "memory usage: 7.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['X', 'Y', 'INDEX_', 'ACCNUM', 'YEAR', 'DATE', 'TIME', 'STREET1',\n",
       "       'STREET2', 'OFFSET', 'ROAD_CLASS', 'DISTRICT', 'WARDNUM',\n",
       "       'LATITUDE', 'LONGITUDE', 'LOCCOORD', 'ACCLOC', 'TRAFFCTL',\n",
       "       'VISIBILITY', 'LIGHT', 'RDSFCOND', 'ACCLASS', 'IMPACTYPE',\n",
       "       'INVTYPE', 'INVAGE', 'INJURY', 'FATAL_NO', 'INITDIR', 'VEHTYPE',\n",
       "       'MANOEUVER', 'DRIVACT', 'DRIVCOND', 'PEDTYPE', 'PEDACT', 'PEDCOND',\n",
       "       'CYCLISTYPE', 'CYCACT', 'CYCCOND', 'PEDESTRIAN', 'CYCLIST',\n",
       "       'AUTOMOBILE', 'MOTORCYCLE', 'TRUCK', 'TRSN_CITY_VEH', 'EMERG_VEH',\n",
       "       'PASSENGER', 'SPEEDING', 'AG_DRIV', 'REDLIGHT', 'ALCOHOL',\n",
       "       'DISABILITY', 'HOOD_158', 'NEIGHBOURHOOD_158', 'HOOD_140',\n",
       "       'NEIGHBOURHOOD_140', 'DIVISION', 'ObjectId'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration <br>\n",
    "Use below code to display categrial data and null counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRIVCOND\n",
      "Normal                                5847\n",
      "Inattentive                           1581\n",
      "Unknown                               1100\n",
      "Medical or Physical Disability         177\n",
      "Had Been Drinking                      163\n",
      "Ability Impaired, Alcohol Over .08     126\n",
      "Ability Impaired, Alcohol              121\n",
      "Other                                   52\n",
      "Fatigue                                 51\n",
      "Ability Impaired, Drugs                 20\n",
      "Name: count, dtype: int64\n",
      "8951\n"
     ]
    }
   ],
   "source": [
    "print(df['DRIVCOND'].value_counts())\n",
    "print(df['DRIVCOND'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine necessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since 5 rows are missing target values (ACCLASS), we will remove them\n",
    "df = df.dropna(subset=['ACCLASS'])\n",
    "\n",
    "#We will remove the columns that are not useful for our model\n",
    "meaningless_columns = ['INDEX_', 'ACCNUM', 'YEAR', 'DATE', 'TIME', 'STREET1',\n",
    "                       'STREET2', 'OFFSET', 'FATAL_NO', 'NEIGHBOURHOOD_158', 'NEIGHBOURHOOD_140',\n",
    "                       'ObjectId']\n",
    "\n",
    "too_much_missing = ['PEDTYPE','CYCACT', 'CYCLISTYPE', 'PEDACT', 'CYCCOND']\n",
    "\n",
    "#We will remove the columns with duplicate information\n",
    "# X and Y are the same as LONGITUDE and LATITUDE\n",
    "# VEHTYPE, PEDCOND, DRIVCOND duplicated because there are categorical columns for the same information\n",
    "duplicate_columns = ['X', 'Y', 'VEHTYPE', 'PEDCOND', 'DRIVCOND']\n",
    "\n",
    "#Columns need to fill missing values as 0\n",
    "fill_zero_columns = ['WARDNUM']\n",
    "\n",
    "#columns need to fill Nan values\n",
    "binary_map = {np.nan: 'No'}\n",
    "fill_nan_columns = ['PEDESTRIAN', 'CYCLIST', 'AUTOMOBILE', 'MOTORCYCLE', 'TRUCK',\n",
    "                    'TRSN_CITY_VEH', 'EMERG_VEH', 'PASSENGER', 'SPEEDING', 'AG_DRIV',\n",
    "                    'REDLIGHT', 'ALCOHOL', 'DISABILITY']\n",
    "\n",
    "#columns which contain categorical data\n",
    "categorical_columns = ['LIGHT', 'INVAGE', 'IMPACTYPE', 'RDSFCOND', \n",
    "                       'DISTRICT', 'DRIVACT', 'INITDIR', 'ROAD_CLASS', 'TRAFFCTL', \n",
    "                       'ACCLOC', 'VISIBILITY','INVTYPE', 'MANOEUVER']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LIGHT            0\n",
       "INVAGE           0\n",
       "IMPACTYPE        4\n",
       "RDSFCOND        25\n",
       "DISTRICT       105\n",
       "DRIVACT       8948\n",
       "INITDIR       5051\n",
       "ROAD_CLASS     376\n",
       "TRAFFCTL        34\n",
       "ACCLOC        5450\n",
       "VISIBILITY      20\n",
       "INVTYPE         16\n",
       "MANOEUVER     7659\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[categorical_columns].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns can be try to exclude or include\n",
    "try_columns = ['DIVISION', 'LOCCOORD', 'INJURY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HOOD_140', 'ACCLASS', 'LATITUDE', 'LONGITUDE', 'HOOD_158']\n"
     ]
    }
   ],
   "source": [
    "#Find remaining columns\n",
    "remaining_columns = list(set(df.columns.values) - set(meaningless_columns) - set(too_much_missing) - set(duplicate_columns) - set(fill_zero_columns) - set(fill_nan_columns) - set(categorical_columns) - set(try_columns))\n",
    "print(remaining_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HOOD_140     0\n",
       "ACCLASS      0\n",
       "LATITUDE     0\n",
       "LONGITUDE    0\n",
       "HOOD_158     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check remaining columns for missing values\n",
    "df[remaining_columns].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a copy of the dataframe\n",
    "df_copy = df.copy()\n",
    "\n",
    "#Drop meaningless columns\n",
    "df_copy = df_copy.drop(columns=meaningless_columns)\n",
    "#Drop too much missing columns\n",
    "df_copy = df_copy.drop(columns=too_much_missing)\n",
    "#Drop duplicate columns\n",
    "df_copy = df_copy.drop(columns=duplicate_columns)\n",
    "#Fill missing values with 'No'\n",
    "df_copy[fill_nan_columns] = df_copy[fill_nan_columns].fillna(value='No')\n",
    "#Fill missing values with 0\n",
    "df_copy[fill_zero_columns] = df_copy[fill_zero_columns].fillna(value=0)\n",
    "\n",
    "#drop y column\n",
    "df_copy = df_copy.drop(columns=['ACCLASS'])\n",
    "\n",
    "#Set y as target variable\n",
    "y = df['ACCLASS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_copy, y, test_size=0.8, random_state=58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3637, 34) (14552, 34) (3637,) (14552,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.replace({'Property Damage Only': 'Non-Fatal Injury'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACCLASS\n",
       "Non-Fatal Injury    15616\n",
       "Fatal                2573\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#tartget values are imbalanced, we will use SMOTE to balance the target values\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m over_sampling\n\u001b[0;32m      3\u001b[0m smote \u001b[38;5;241m=\u001b[39m over_sampling\u001b[38;5;241m.\u001b[39mSMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m58\u001b[39m)\n\u001b[0;32m      4\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m smote\u001b[38;5;241m.\u001b[39mfit_resample(X_train, y_train)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\imblearn\\__init__.py:52\u001b[0m\n\u001b[0;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     53\u001b[0m         combine,\n\u001b[0;32m     54\u001b[0m         ensemble,\n\u001b[0;32m     55\u001b[0m         exceptions,\n\u001b[0;32m     56\u001b[0m         metrics,\n\u001b[0;32m     57\u001b[0m         over_sampling,\n\u001b[0;32m     58\u001b[0m         pipeline,\n\u001b[0;32m     59\u001b[0m         tensorflow,\n\u001b[0;32m     60\u001b[0m         under_sampling,\n\u001b[0;32m     61\u001b[0m         utils,\n\u001b[0;32m     62\u001b[0m     )\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\imblearn\\combine\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\imblearn\\combine\\_smote_enn.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\imblearn\\base.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_sampling_strategy, check_target_type\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArraysTransformer\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSamplerMixin\u001b[39;00m(BaseEstimator, metaclass\u001b[38;5;241m=\u001b[39mABCMeta):\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\imblearn\\utils\\_param_validation.py:908\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_valid_param  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m    907\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m--> 908\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    909\u001b[0m     HasMethods,\n\u001b[0;32m    910\u001b[0m     Hidden,\n\u001b[0;32m    911\u001b[0m     Interval,\n\u001b[0;32m    912\u001b[0m     Options,\n\u001b[0;32m    913\u001b[0m     StrOptions,\n\u001b[0;32m    914\u001b[0m     _ArrayLikes,\n\u001b[0;32m    915\u001b[0m     _Booleans,\n\u001b[0;32m    916\u001b[0m     _Callables,\n\u001b[0;32m    917\u001b[0m     _CVObjects,\n\u001b[0;32m    918\u001b[0m     _InstancesOf,\n\u001b[0;32m    919\u001b[0m     _IterablesNotString,\n\u001b[0;32m    920\u001b[0m     _MissingValues,\n\u001b[0;32m    921\u001b[0m     _NoneConstraint,\n\u001b[0;32m    922\u001b[0m     _PandasNAConstraint,\n\u001b[0;32m    923\u001b[0m     _RandomStates,\n\u001b[0;32m    924\u001b[0m     _SparseMatrices,\n\u001b[0;32m    925\u001b[0m     _VerboseHelper,\n\u001b[0;32m    926\u001b[0m     make_constraint,\n\u001b[0;32m    927\u001b[0m     validate_params,\n\u001b[0;32m    928\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py)"
     ]
    }
   ],
   "source": [
    "#tartget values are imbalanced, we will use SMOTE to balance the target values\n",
    "from imblearn import over_sampling\n",
    "smote = over_sampling.SMOTE(random_state=58)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a pipeline to transform the data\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "#Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "#Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, remaining_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns)\n",
    "    ])\n",
    "\n",
    "#Define the model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "#Bundle preprocessing and modeling code in a pipeline\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', model)\n",
    "                     ])\n",
    "\n",
    "#Preprocessing of training data, fit model\n",
    "clf.fit(df_copy, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCLASS\n",
      "Non-Fatal Injury        15599\n",
      "Fatal                    2573\n",
      "Property Damage Only       17\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Mapping for target column\n",
    "print(df['ACCLASS'].value_counts())\n",
    "\n",
    "# Only Fatal and Non-Fatal from our prediction\n",
    "# 1 for Fatal, 0 for Non-Fatal\n",
    "data_map = {\n",
    "    'Fatal': 1, \n",
    "    'Non-Fatal Injury': 0, \n",
    "    'Property Damage Only': 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>INDEX_</th>\n",
       "      <th>ACCNUM</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>TIME</th>\n",
       "      <th>WARDNUM</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>FATAL_NO</th>\n",
       "      <th>ObjectId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.819400e+04</td>\n",
       "      <td>1.819400e+04</td>\n",
       "      <td>1.819400e+04</td>\n",
       "      <td>1.326400e+04</td>\n",
       "      <td>18194.000000</td>\n",
       "      <td>18194.000000</td>\n",
       "      <td>1.733200e+04</td>\n",
       "      <td>18194.000000</td>\n",
       "      <td>18194.000000</td>\n",
       "      <td>827.000000</td>\n",
       "      <td>18194.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-8.838345e+06</td>\n",
       "      <td>5.420748e+06</td>\n",
       "      <td>3.818870e+07</td>\n",
       "      <td>4.248444e+08</td>\n",
       "      <td>2012.934869</td>\n",
       "      <td>1362.615917</td>\n",
       "      <td>2.521028e+03</td>\n",
       "      <td>43.710459</td>\n",
       "      <td>-79.396201</td>\n",
       "      <td>29.073761</td>\n",
       "      <td>9097.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.162533e+04</td>\n",
       "      <td>8.682160e+03</td>\n",
       "      <td>3.726463e+07</td>\n",
       "      <td>1.065503e+09</td>\n",
       "      <td>4.754258</td>\n",
       "      <td>630.816048</td>\n",
       "      <td>1.844803e+05</td>\n",
       "      <td>0.056369</td>\n",
       "      <td>0.104432</td>\n",
       "      <td>17.803627</td>\n",
       "      <td>5252.299734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-8.865305e+06</td>\n",
       "      <td>5.402162e+06</td>\n",
       "      <td>3.363207e+06</td>\n",
       "      <td>2.530100e+04</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>43.589678</td>\n",
       "      <td>-79.638390</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.846591e+06</td>\n",
       "      <td>5.413242e+06</td>\n",
       "      <td>5.391370e+06</td>\n",
       "      <td>1.021229e+06</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>920.000000</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>43.661727</td>\n",
       "      <td>-79.470280</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4549.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-8.838448e+06</td>\n",
       "      <td>5.419556e+06</td>\n",
       "      <td>7.644612e+06</td>\n",
       "      <td>1.197308e+06</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>1450.000000</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>43.702745</td>\n",
       "      <td>-79.397132</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>9097.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-8.829671e+06</td>\n",
       "      <td>5.427813e+06</td>\n",
       "      <td>8.078261e+07</td>\n",
       "      <td>1.365020e+06</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>1850.000000</td>\n",
       "      <td>2.200000e+01</td>\n",
       "      <td>43.756345</td>\n",
       "      <td>-79.318286</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>13645.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-8.807929e+06</td>\n",
       "      <td>5.443099e+06</td>\n",
       "      <td>8.170606e+07</td>\n",
       "      <td>4.008024e+09</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2359.000000</td>\n",
       "      <td>1.716222e+07</td>\n",
       "      <td>43.855445</td>\n",
       "      <td>-79.122974</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>18194.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  X             Y        INDEX_        ACCNUM          YEAR  \\\n",
       "count  1.819400e+04  1.819400e+04  1.819400e+04  1.326400e+04  18194.000000   \n",
       "mean  -8.838345e+06  5.420748e+06  3.818870e+07  4.248444e+08   2012.934869   \n",
       "std    1.162533e+04  8.682160e+03  3.726463e+07  1.065503e+09      4.754258   \n",
       "min   -8.865305e+06  5.402162e+06  3.363207e+06  2.530100e+04   2006.000000   \n",
       "25%   -8.846591e+06  5.413242e+06  5.391370e+06  1.021229e+06   2009.000000   \n",
       "50%   -8.838448e+06  5.419556e+06  7.644612e+06  1.197308e+06   2012.000000   \n",
       "75%   -8.829671e+06  5.427813e+06  8.078261e+07  1.365020e+06   2017.000000   \n",
       "max   -8.807929e+06  5.443099e+06  8.170606e+07  4.008024e+09   2022.000000   \n",
       "\n",
       "               TIME       WARDNUM      LATITUDE     LONGITUDE    FATAL_NO  \\\n",
       "count  18194.000000  1.733200e+04  18194.000000  18194.000000  827.000000   \n",
       "mean    1362.615917  2.521028e+03     43.710459    -79.396201   29.073761   \n",
       "std      630.816048  1.844803e+05      0.056369      0.104432   17.803627   \n",
       "min        0.000000  1.000000e+00     43.589678    -79.638390    1.000000   \n",
       "25%      920.000000  7.000000e+00     43.661727    -79.470280   14.000000   \n",
       "50%     1450.000000  1.300000e+01     43.702745    -79.397132   28.000000   \n",
       "75%     1850.000000  2.200000e+01     43.756345    -79.318286   42.000000   \n",
       "max     2359.000000  1.716222e+07     43.855445    -79.122974   78.000000   \n",
       "\n",
       "           ObjectId  \n",
       "count  18194.000000  \n",
       "mean    9097.500000  \n",
       "std     5252.299734  \n",
       "min        1.000000  \n",
       "25%     4549.250000  \n",
       "50%     9097.500000  \n",
       "75%    13645.750000  \n",
       "max    18194.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
