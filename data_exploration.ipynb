{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Project - KSI data - Classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Target Column***\n",
    "ACCLASS<br>\n",
    "Required to transform into binary (0, 1):<br>\n",
    "'Fatal' --> 1, <br>\n",
    "'Non-Fatal Injury' --> 0, <br>\n",
    "'Property Damage Only' --> 0, <br>\n",
    "***5 nan value from this column, we can consider to drop them***\n",
    "\n",
    "\n",
    "\n",
    "below columns need to fill values:\n",
    "'PEDESTRIAN', 'CYCLIST', 'AUTOMOBILE', 'MOTORCYCLE', 'TRUCK',\n",
    "'TRSN_CITY_VEH', 'EMERG_VEH', 'PASSENGER', 'SPEEDING', 'AG_DRIV',\n",
    "'REDLIGHT', 'ALCOHOL', 'DISABILITY'\n",
    "fill Nan as No, and transform to 0, 1\n",
    "(Default they are Yes, Nan values)\n",
    "ROAD_CLASS fill most freq value\n",
    "DISTRICT fill most freq value\n",
    "\n",
    "Questionable column:\n",
    "CYCCOND: multi categories, fill Nan as most freq value??\n",
    "\n",
    "\n",
    "From the dataset, below columns are unnecessary:\n",
    "ObjectId, HEIGHBOURHOOD_158, HEIGHBOURHOOD_140, CYCLISTYPE(too much categories and too much Nan value),<br>\n",
    "PEDCOND(too much categories and too much Nan value), PEDACT(too much categories and too much Nan value),<br>\n",
    "PEDTYPE (too much categories and too much Nan value), DRICOND ('other' included, means it is not a accuracy value), DRIVACT ('other' included, means it is not a accuracy value), MANOEUVER('other' included, means it is not a accuracy value)<br>\n",
    "FATAL_NO, INVTYPE, DATE, YEAR, ACCNUM, INDEX_, STREET1, STREET2, OFFSET, X, Y,INJURY\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r'dataset\\KSI.csv'\n",
    "\n",
    "df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>INDEX_</th>\n",
       "      <th>ACCNUM</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>STREET1</th>\n",
       "      <th>STREET2</th>\n",
       "      <th>OFFSET</th>\n",
       "      <th>...</th>\n",
       "      <th>AG_DRIV</th>\n",
       "      <th>REDLIGHT</th>\n",
       "      <th>ALCOHOL</th>\n",
       "      <th>DISABILITY</th>\n",
       "      <th>HOOD_158</th>\n",
       "      <th>NEIGHBOURHOOD_158</th>\n",
       "      <th>HOOD_140</th>\n",
       "      <th>NEIGHBOURHOOD_140</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>ObjectId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8.844611e+06</td>\n",
       "      <td>5.412414e+06</td>\n",
       "      <td>3387730</td>\n",
       "      <td>892658.0</td>\n",
       "      <td>2006</td>\n",
       "      <td>2006/03/11 05:00:00+00</td>\n",
       "      <td>852</td>\n",
       "      <td>BLOOR ST W</td>\n",
       "      <td>DUNDAS ST W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88</td>\n",
       "      <td>High Park North</td>\n",
       "      <td>88</td>\n",
       "      <td>High Park North (88)</td>\n",
       "      <td>D11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-8.844611e+06</td>\n",
       "      <td>5.412414e+06</td>\n",
       "      <td>3387731</td>\n",
       "      <td>892658.0</td>\n",
       "      <td>2006</td>\n",
       "      <td>2006/03/11 05:00:00+00</td>\n",
       "      <td>852</td>\n",
       "      <td>BLOOR ST W</td>\n",
       "      <td>DUNDAS ST W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88</td>\n",
       "      <td>High Park North</td>\n",
       "      <td>88</td>\n",
       "      <td>High Park North (88)</td>\n",
       "      <td>D11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.816480e+06</td>\n",
       "      <td>5.434843e+06</td>\n",
       "      <td>3388101</td>\n",
       "      <td>892810.0</td>\n",
       "      <td>2006</td>\n",
       "      <td>2006/03/11 05:00:00+00</td>\n",
       "      <td>915</td>\n",
       "      <td>MORNINGSIDE AVE</td>\n",
       "      <td>SHEPPARD AVE E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146</td>\n",
       "      <td>Malvern East</td>\n",
       "      <td>132</td>\n",
       "      <td>Malvern (132)</td>\n",
       "      <td>D42</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-8.829728e+06</td>\n",
       "      <td>5.419071e+06</td>\n",
       "      <td>3389067</td>\n",
       "      <td>893184.0</td>\n",
       "      <td>2006</td>\n",
       "      <td>2006/01/01 05:00:00+00</td>\n",
       "      <td>236</td>\n",
       "      <td>WOODBINE AVE</td>\n",
       "      <td>O CONNOR DR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>Woodbine-Lumsden</td>\n",
       "      <td>60</td>\n",
       "      <td>Woodbine-Lumsden (60)</td>\n",
       "      <td>D55</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-8.816480e+06</td>\n",
       "      <td>5.434843e+06</td>\n",
       "      <td>3388102</td>\n",
       "      <td>892810.0</td>\n",
       "      <td>2006</td>\n",
       "      <td>2006/03/11 05:00:00+00</td>\n",
       "      <td>915</td>\n",
       "      <td>MORNINGSIDE AVE</td>\n",
       "      <td>SHEPPARD AVE E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146</td>\n",
       "      <td>Malvern East</td>\n",
       "      <td>132</td>\n",
       "      <td>Malvern (132)</td>\n",
       "      <td>D42</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              X             Y   INDEX_    ACCNUM  YEAR  \\\n",
       "0 -8.844611e+06  5.412414e+06  3387730  892658.0  2006   \n",
       "1 -8.844611e+06  5.412414e+06  3387731  892658.0  2006   \n",
       "2 -8.816480e+06  5.434843e+06  3388101  892810.0  2006   \n",
       "3 -8.829728e+06  5.419071e+06  3389067  893184.0  2006   \n",
       "4 -8.816480e+06  5.434843e+06  3388102  892810.0  2006   \n",
       "\n",
       "                     DATE  TIME          STREET1         STREET2 OFFSET  ...  \\\n",
       "0  2006/03/11 05:00:00+00   852       BLOOR ST W     DUNDAS ST W    NaN  ...   \n",
       "1  2006/03/11 05:00:00+00   852       BLOOR ST W     DUNDAS ST W    NaN  ...   \n",
       "2  2006/03/11 05:00:00+00   915  MORNINGSIDE AVE  SHEPPARD AVE E    NaN  ...   \n",
       "3  2006/01/01 05:00:00+00   236     WOODBINE AVE     O CONNOR DR    NaN  ...   \n",
       "4  2006/03/11 05:00:00+00   915  MORNINGSIDE AVE  SHEPPARD AVE E    NaN  ...   \n",
       "\n",
       "  AG_DRIV REDLIGHT  ALCOHOL  DISABILITY  HOOD_158 NEIGHBOURHOOD_158 HOOD_140  \\\n",
       "0     Yes      NaN      NaN         NaN        88   High Park North       88   \n",
       "1     Yes      NaN      NaN         NaN        88   High Park North       88   \n",
       "2     Yes      Yes      NaN         NaN       146      Malvern East      132   \n",
       "3     Yes      NaN      Yes         NaN        60  Woodbine-Lumsden       60   \n",
       "4     Yes      Yes      NaN         NaN       146      Malvern East      132   \n",
       "\n",
       "       NEIGHBOURHOOD_140 DIVISION ObjectId  \n",
       "0   High Park North (88)      D11        1  \n",
       "1   High Park North (88)      D11        2  \n",
       "2          Malvern (132)      D42        3  \n",
       "3  Woodbine-Lumsden (60)      D55        4  \n",
       "4          Malvern (132)      D42        5  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18194 entries, 0 to 18193\n",
      "Data columns (total 57 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   X                  18194 non-null  float64\n",
      " 1   Y                  18194 non-null  float64\n",
      " 2   INDEX_             18194 non-null  int64  \n",
      " 3   ACCNUM             13264 non-null  float64\n",
      " 4   YEAR               18194 non-null  int64  \n",
      " 5   DATE               18194 non-null  object \n",
      " 6   TIME               18194 non-null  int64  \n",
      " 7   STREET1            18194 non-null  object \n",
      " 8   STREET2            16510 non-null  object \n",
      " 9   OFFSET             3402 non-null   object \n",
      " 10  ROAD_CLASS         17818 non-null  object \n",
      " 11  DISTRICT           18089 non-null  object \n",
      " 12  WARDNUM            17332 non-null  float64\n",
      " 13  LATITUDE           18194 non-null  float64\n",
      " 14  LONGITUDE          18194 non-null  float64\n",
      " 15  LOCCOORD           18099 non-null  object \n",
      " 16  ACCLOC             12744 non-null  object \n",
      " 17  TRAFFCTL           18160 non-null  object \n",
      " 18  VISIBILITY         18174 non-null  object \n",
      " 19  LIGHT              18194 non-null  object \n",
      " 20  RDSFCOND           18169 non-null  object \n",
      " 21  ACCLASS            18189 non-null  object \n",
      " 22  IMPACTYPE          18190 non-null  object \n",
      " 23  INVTYPE            18178 non-null  object \n",
      " 24  INVAGE             18194 non-null  object \n",
      " 25  INJURY             9627 non-null   object \n",
      " 26  FATAL_NO           827 non-null    float64\n",
      " 27  INITDIR            13142 non-null  object \n",
      " 28  VEHTYPE            14966 non-null  object \n",
      " 29  MANOEUVER          10534 non-null  object \n",
      " 30  DRIVACT            9243 non-null   object \n",
      " 31  DRIVCOND           9240 non-null   object \n",
      " 32  PEDTYPE            3060 non-null   object \n",
      " 33  PEDACT             3082 non-null   object \n",
      " 34  PEDCOND            3084 non-null   object \n",
      " 35  CYCLISTYPE         774 non-null    object \n",
      " 36  CYCACT             766 non-null    object \n",
      " 37  CYCCOND            765 non-null    object \n",
      " 38  PEDESTRIAN         7354 non-null   object \n",
      " 39  CYCLIST            1906 non-null   object \n",
      " 40  AUTOMOBILE         16550 non-null  object \n",
      " 41  MOTORCYCLE         1587 non-null   object \n",
      " 42  TRUCK              1122 non-null   object \n",
      " 43  TRSN_CITY_VEH      1110 non-null   object \n",
      " 44  EMERG_VEH          43 non-null     object \n",
      " 45  PASSENGER          6906 non-null   object \n",
      " 46  SPEEDING           2575 non-null   object \n",
      " 47  AG_DRIV            9460 non-null   object \n",
      " 48  REDLIGHT           1520 non-null   object \n",
      " 49  ALCOHOL            788 non-null    object \n",
      " 50  DISABILITY         486 non-null    object \n",
      " 51  HOOD_158           18194 non-null  object \n",
      " 52  NEIGHBOURHOOD_158  18194 non-null  object \n",
      " 53  HOOD_140           18194 non-null  object \n",
      " 54  NEIGHBOURHOOD_140  18194 non-null  object \n",
      " 55  DIVISION           18194 non-null  object \n",
      " 56  ObjectId           18194 non-null  int64  \n",
      "dtypes: float64(7), int64(4), object(46)\n",
      "memory usage: 7.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['X', 'Y', 'INDEX_', 'ACCNUM', 'YEAR', 'DATE', 'TIME', 'STREET1',\n",
       "       'STREET2', 'OFFSET', 'ROAD_CLASS', 'DISTRICT', 'WARDNUM',\n",
       "       'LATITUDE', 'LONGITUDE', 'LOCCOORD', 'ACCLOC', 'TRAFFCTL',\n",
       "       'VISIBILITY', 'LIGHT', 'RDSFCOND', 'ACCLASS', 'IMPACTYPE',\n",
       "       'INVTYPE', 'INVAGE', 'INJURY', 'FATAL_NO', 'INITDIR', 'VEHTYPE',\n",
       "       'MANOEUVER', 'DRIVACT', 'DRIVCOND', 'PEDTYPE', 'PEDACT', 'PEDCOND',\n",
       "       'CYCLISTYPE', 'CYCACT', 'CYCCOND', 'PEDESTRIAN', 'CYCLIST',\n",
       "       'AUTOMOBILE', 'MOTORCYCLE', 'TRUCK', 'TRSN_CITY_VEH', 'EMERG_VEH',\n",
       "       'PASSENGER', 'SPEEDING', 'AG_DRIV', 'REDLIGHT', 'ALCOHOL',\n",
       "       'DISABILITY', 'HOOD_158', 'NEIGHBOURHOOD_158', 'HOOD_140',\n",
       "       'NEIGHBOURHOOD_140', 'DIVISION', 'ObjectId'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration <br>\n",
    "Use below code to display categrial data and null counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRIVCOND\n",
      "Normal                                5849\n",
      "Inattentive                           1581\n",
      "Unknown                               1100\n",
      "Medical or Physical Disability         177\n",
      "Had Been Drinking                      163\n",
      "Ability Impaired, Alcohol Over .08     126\n",
      "Ability Impaired, Alcohol              121\n",
      "Other                                   52\n",
      "Fatigue                                 51\n",
      "Ability Impaired, Drugs                 20\n",
      "Name: count, dtype: int64\n",
      "8954\n"
     ]
    }
   ],
   "source": [
    "print(df['DRIVCOND'].value_counts())\n",
    "print(df['DRIVCOND'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since 5 rows are missing target values (ACCLASS), we will remove them\n",
    "df = df.dropna(subset=['ACCLASS'])\n",
    "\n",
    "#We will remove the columns that are not useful for our model\n",
    "meaningless_columns = ['INDEX_', 'ACCNUM', 'YEAR', 'DATE', 'TIME', 'STREET1',\n",
    "                       'STREET2', 'OFFSET', 'FATAL_NO', 'NEIGHBOURHOOD_158', 'NEIGHBOURHOOD_140',\n",
    "                       'ObjectId', 'WARDNUM', 'DIVISION']\n",
    "\n",
    "too_much_missing = ['PEDTYPE','CYCACT', 'CYCLISTYPE', 'PEDACT', 'CYCCOND', 'MANOEUVER']\n",
    "\n",
    "#We will remove the columns with duplicate information\n",
    "# X and Y are the same as LONGITUDE and LATITUDE\n",
    "# VEHTYPE, PEDCOND, DRIVCOND, IMPACTYPE, DRIVACT duplicated because there are categorical columns for the same information\n",
    "duplicated_columns = ['X', 'Y', 'VEHTYPE', 'PEDCOND', 'DRIVCOND', 'IMPACTYPE','LOCCOORD']\n",
    "\n",
    "\n",
    "#columns need to fill Nan values\n",
    "binary_map = {np.nan: 'No'}\n",
    "fill_nan_columns = ['PEDESTRIAN', 'CYCLIST', 'AUTOMOBILE', 'MOTORCYCLE', 'TRUCK',\n",
    "                    'TRSN_CITY_VEH', 'EMERG_VEH', 'PASSENGER', 'SPEEDING', 'AG_DRIV',\n",
    "                    'REDLIGHT', 'ALCOHOL', 'DISABILITY']\n",
    "\n",
    "#columns which contain categorical data\n",
    "categorical_columns = ['LIGHT', 'INVAGE', 'RDSFCOND', \n",
    "                       'DISTRICT', 'INITDIR', 'ROAD_CLASS', 'TRAFFCTL', \n",
    "                       'ACCLOC', 'VISIBILITY','INVTYPE']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the dataframe\n",
    "df_origin = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop meaningless columns, duplicated columns and columns with too much missing values\n",
    "df = df.drop(columns=meaningless_columns)\n",
    "df = df.drop(columns=duplicated_columns)\n",
    "df = df.drop(columns=too_much_missing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with columns which contains many catefories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simplfy the categorical data\n",
    "# LIGHT\n",
    "# Daylight                10385\n",
    "# Dark                     3687\n",
    "# Dark, artificial         3300\n",
    "# Dusk                      240\n",
    "# Dusk, artificial          219\n",
    "# Daylight, artificial      141\n",
    "# Dawn                      110\n",
    "# Dawn, artificial          101\n",
    "# Other                       6\n",
    "\n",
    "#We will simplify the LIGHT column to Daylight, Dark, Dusk, Dawn, Other\n",
    "light_map = {\n",
    "    'Daylight': 'Daylight', \n",
    "    'Dark': 'Dark', \n",
    "    'Dark, artificial': 'Dark', \n",
    "    'Dusk': 'Dusk', \n",
    "    'Dusk, artificial': 'Dusk',         \n",
    "    'Daylight, artificial': 'Daylight', \n",
    "    'Dawn': 'Dawn', \n",
    "    'Dawn, artificial': 'Dawn', \n",
    "    'Other': 'Other'\n",
    "    }\n",
    "\n",
    "df['LIGHT'] = df['LIGHT'].map(light_map)\n",
    "\n",
    "# IMPACTYPE\n",
    "# Pedestrian Collisions     7293\n",
    "# Turning Movement          2792\n",
    "# Cyclist Collisions        1795\n",
    "# Rear End                  1746\n",
    "# SMV Other                 1457\n",
    "# Angle                     1283\n",
    "# Approaching                928\n",
    "# Sideswipe                  506\n",
    "# Other                      195\n",
    "# SMV Unattended Vehicle     190\n",
    "# Name: count, dtype: int64\n",
    "# Null Values: 4\n",
    "\n",
    "#Pedestrian, Cyclist are representing IMPACTYPE column, so we will drop it\n",
    "\n",
    "# INVAGE\n",
    "# unknown     2609\n",
    "# 20 to 24    1710\n",
    "# 25 to 29    1638\n",
    "# 30 to 34    1384\n",
    "# 35 to 39    1311\n",
    "# 50 to 54    1302\n",
    "# 40 to 44    1274\n",
    "# 45 to 49    1239\n",
    "# 55 to 59    1098\n",
    "# 60 to 64     877\n",
    "# 15 to 19     852\n",
    "# 65 to 69     681\n",
    "# 70 to 74     529\n",
    "# 75 to 79     434\n",
    "# 80 to 84     336\n",
    "# 10 to 14     249\n",
    "# 85 to 89     212\n",
    "# 5 to 9       199\n",
    "# 0 to 4       177\n",
    "# 90 to 94      63\n",
    "# Over 95       15\n",
    "# Name: count, dtype: int64\n",
    "# Null Values: 0\n",
    "\n",
    "#We will simplify the INVAGE column to 0 to 20, 20 to 40, 40 to 60, 60 to 80, over 80\n",
    "invage_map = {\n",
    "    'unknown': 'unknown',\n",
    "    '20 to 24': '20 to 40',\n",
    "    '25 to 29': '20 to 40',\n",
    "    '30 to 34': '20 to 40',\n",
    "    '35 to 39': '20 to 40',\n",
    "    '50 to 54': '40 to 60',\n",
    "    '40 to 44': '40 to 60',\n",
    "    '45 to 49': '40 to 60',\n",
    "    '55 to 59': '40 to 60',\n",
    "    '60 to 64': '60 to 80',\n",
    "    '15 to 19': '0 to 20',\n",
    "    '65 to 69': '60 to 80',\n",
    "    '70 to 74': '60 to 80',\n",
    "    '75 to 79': '60 to 80',\n",
    "    '80 to 84': 'over 80',\n",
    "    '10 to 14': '0 to 20',\n",
    "    '85 to 89': 'over 80',\n",
    "    '5 to 9': '0 to 20',\n",
    "    '0 to 4': '0 to 20',\n",
    "    '90 to 94': 'over 80',\n",
    "    'Over 95': 'over 80'\n",
    "    }\n",
    "\n",
    "df['INVAGE'] = df['INVAGE'].map(invage_map)\n",
    "\n",
    "# RDSFCOND\n",
    "# Dry                     14594\n",
    "# Wet                      3021\n",
    "# Loose Snow                169\n",
    "# Other                     145\n",
    "# Slush                     102\n",
    "# Ice                        77\n",
    "# Packed Snow                44\n",
    "# Loose Sand or Gravel       11\n",
    "# Spilled liquid              1\n",
    "# Name: count, dtype: int64\n",
    "# Null Values: 25\n",
    "\n",
    "#We will simplify the RDSFCOND column to Dry, Wet, Snow, Ice, Other\n",
    "rdsfcond_map = {\n",
    "    'Dry': 'Dry',\n",
    "    'Wet': 'Wet',\n",
    "    'Loose Snow': 'Snow',\n",
    "    'Other': 'Other',\n",
    "    'Slush': 'Snow',\n",
    "    'Ice': 'Ice',\n",
    "    'Packed Snow': 'Snow',\n",
    "    'Loose Sand or Gravel': 'Other',\n",
    "    'Spilled liquid': 'Other'\n",
    "    }\n",
    "\n",
    "df['RDSFCOND'] = df['RDSFCOND'].map(rdsfcond_map)\n",
    "\n",
    "# fill the missing values with other\n",
    "df['RDSFCOND'] = df['RDSFCOND'].fillna('Other')\n",
    "\n",
    "# DISTRICT\n",
    "# Toronto and East York    6125\n",
    "# Etobicoke York           4207\n",
    "# Scarborough              4111\n",
    "# North York               3637\n",
    "# Toronto East York           4\n",
    "# Name: count, dtype: int64\n",
    "# Null Values: 105\n",
    "\n",
    "# DISTRICT column has 105 missing values, we will fill them with the most frequent value\n",
    "df['DISTRICT'] = df['DISTRICT'].fillna(df['DISTRICT'].mode()[0])\n",
    "\n",
    "# DRIVACT\n",
    "# Driving Properly                4221\n",
    "# Failed to Yield Right of Way    1541\n",
    "# Lost control                     975\n",
    "# Improper Turn                    573\n",
    "# Other                            504\n",
    "# Disobeyed Traffic Control        475\n",
    "# Following too Close              251\n",
    "# Exceeding Speed Limit            246\n",
    "# Speed too Fast For Condition     208\n",
    "# Improper Lane Change             122\n",
    "# Improper Passing                 112\n",
    "# Wrong Way on One Way Road          9\n",
    "# Speed too Slow                     4\n",
    "# Name: count, dtype: int64\n",
    "# Null Values: 8948\n",
    "\n",
    "#Redlight, Speeding, Ag_Driv, Alcohol, Disability are representing DRIVACT column, so we will drop it\n",
    "\n",
    "# INITDIR\n",
    "# East       3259\n",
    "# West       3197\n",
    "# South      3106\n",
    "# North      3066\n",
    "# Unknown     510\n",
    "# Name: count, dtype: int64\n",
    "# Null Values: 5051\n",
    "\n",
    "# INITDIR column has 5051 missing values, we will fill them with Unknown\n",
    "df['INITDIR'] = df['INITDIR'].fillna('Unknown')\n",
    "\n",
    "# ROAD_CLASS\n",
    "# Major Arterial         12951\n",
    "# Minor Arterial          2840\n",
    "# Collector                996\n",
    "# Local                    841\n",
    "# Expressway               132\n",
    "# Other                     25\n",
    "# Laneway                   11\n",
    "# Expressway Ramp            9\n",
    "# Pending                    7\n",
    "# Major Arterial Ramp        1\n",
    "# Name: count, dtype: int64\n",
    "# Null Values: 376\n",
    "\n",
    "# Simplify the ROAD_CLASS column to Major Arterial, Minor Arterial, Collector, Local, Other\n",
    "road_class_map = {\n",
    "    'Major Arterial': 'Major Arterial',\n",
    "    'Minor Arterial': 'Minor Arterial',\n",
    "    'Collector': 'Collector',\n",
    "    'Local': 'Local',\n",
    "    'Expressway': 'Other',\n",
    "    'Other': 'Other',\n",
    "    'Laneway': 'Other',\n",
    "    'Expressway Ramp': 'Other',\n",
    "    'Pending': 'Other',\n",
    "    'Major Arterial Ramp': 'Other'\n",
    "    }\n",
    "\n",
    "df['ROAD_CLASS'] = df['ROAD_CLASS'].map(road_class_map)\n",
    "\n",
    "# Fill the missing values with Other\n",
    "df['ROAD_CLASS'] = df['ROAD_CLASS'].fillna('Other')\n",
    "\n",
    "# TRAFFCTL\n",
    "# No Control              8788\n",
    "# Traffic Signal          7635\n",
    "# Stop Sign               1380\n",
    "# Pedestrian Crossover     198\n",
    "# Traffic Controller       108\n",
    "# Yield Sign                21\n",
    "# Streetcar (Stop for)      16\n",
    "# Traffic Gate               5\n",
    "# School Guard               2\n",
    "# Police Control             2\n",
    "# Name: count, dtype: int64\n",
    "# Null Values: 34\n",
    "\n",
    "# Simplyfy the TRAFFCTL column to No Control, Traffic Signal, Stop Sign, Other\n",
    "traffctl_map = {\n",
    "    'No Control': 'No Control',\n",
    "    'Traffic Signal': 'Traffic Signal',\n",
    "    'Stop Sign': 'Stop Sign',\n",
    "    'Pedestrian Crossover': 'Other',\n",
    "    'Traffic Controller': 'Other',\n",
    "    'Yield Sign': 'Other',\n",
    "    'Streetcar (Stop for)': 'Other',\n",
    "    'Traffic Gate': 'Other',\n",
    "    'School Guard': 'Other',\n",
    "    'Police Control': 'Other'\n",
    "    }\n",
    "\n",
    "df['TRAFFCTL'] = df['TRAFFCTL'].map(traffctl_map)\n",
    "\n",
    "# Fill the missing values with Other\n",
    "df['TRAFFCTL'] = df['TRAFFCTL'].fillna('Other')\n",
    "\n",
    "# ACCLOC\n",
    "# At Intersection          8689\n",
    "# Non Intersection         2420\n",
    "# Intersection Related     1200\n",
    "# At/Near Private Drive     379\n",
    "# Overpass or Bridge         17\n",
    "# Laneway                    14\n",
    "# Private Driveway           13\n",
    "# Underpass or Tunnel         6\n",
    "# Trail                       1\n",
    "# Name: count, dtype: int64\n",
    "# Null Values: 5450\n",
    "\n",
    "# Simplyfy the ACCLOC column to At Intersection, Non Intersection, Other\n",
    "accloc_map = {\n",
    "    'At Intersection': 'At Intersection',\n",
    "    'Non Intersection': 'Non Intersection',\n",
    "    'Intersection Related': 'At Intersection',\n",
    "    'At/Near Private Drive': 'Other',\n",
    "    'Overpass or Bridge': 'Other',\n",
    "    'Laneway': 'Other',\n",
    "    'Private Driveway': 'Other',\n",
    "    'Underpass or Tunnel': 'Other',\n",
    "    'Trail': 'Other'\n",
    "    }   \n",
    "\n",
    "df['ACCLOC'] = df['ACCLOC'].map(accloc_map)\n",
    "\n",
    "# Fill the missing values with Other\n",
    "df['ACCLOC'] = df['ACCLOC'].fillna('Other')\n",
    "\n",
    "# VISIBILITY\n",
    "# Clear                     15714\n",
    "# Rain                       1879\n",
    "# Snow                        351\n",
    "# Other                        97\n",
    "# Fog, Mist, Smoke, Dust       50\n",
    "# Freezing Rain                47\n",
    "# Drifting Snow                21\n",
    "# Strong wind                  10\n",
    "# Name: count, dtype: int64\n",
    "# Null Values: 20\n",
    "\n",
    "# Simplyfy the VISIBILITY column to Clear, Rain, Snow, Other\n",
    "\n",
    "visibility_map = {\n",
    "    'Clear': 'Clear',\n",
    "    'Rain': 'Rain',\n",
    "    'Snow': 'Snow',\n",
    "    'Other': 'Other',\n",
    "    'Fog, Mist, Smoke, Dust': 'Other',\n",
    "    'Freezing Rain': 'Other',\n",
    "    'Drifting Snow': 'Other',\n",
    "    'Strong wind': 'Other'\n",
    "    }\n",
    "\n",
    "df['VISIBILITY'] = df['VISIBILITY'].map(visibility_map)\n",
    "\n",
    "# Fill the missing values with Other\n",
    "df['VISIBILITY'] = df['VISIBILITY'].fillna('Other')\n",
    "\n",
    "# INVTYPE\n",
    "# Driver                  8274\n",
    "# Pedestrian              3110\n",
    "# Passenger               2766\n",
    "# Vehicle Owner           1637\n",
    "# Cyclist                  784\n",
    "# Motorcycle Driver        697\n",
    "# Truck Driver             346\n",
    "# Other Property Owner     257\n",
    "# Other                    186\n",
    "# Motorcycle Passenger      39\n",
    "# Moped Driver              30\n",
    "# Driver - Not Hit          17\n",
    "# Wheelchair                17\n",
    "# In-Line Skater             5\n",
    "# Cyclist Passenger          3\n",
    "# Trailer Owner              2\n",
    "# Pedestrian - Not Hit       1\n",
    "# Witness                    1\n",
    "# Moped Passenger            1\n",
    "# Name: count, dtype: int64\n",
    "# Null Values: 16\n",
    "\n",
    "# Simplyfy the INVTYPE column to Driver, Pedestrian, Passenger, Vehicle Owner, Cyclist, Other\n",
    "\n",
    "invtype_map = {\n",
    "    'Driver': 'Driver',\n",
    "    'Pedestrian': 'Pedestrian',\n",
    "    'Passenger': 'Passenger',\n",
    "    'Vehicle Owner': 'Vehicle Owner',\n",
    "    'Cyclist': 'Cyclist',\n",
    "    'Motorcycle Driver': 'Driver',\n",
    "    'Truck Driver': 'Driver',\n",
    "    'Other Property Owner': 'Other',\n",
    "    'Other': 'Other',\n",
    "    'Motorcycle Passenger': 'Passenger',\n",
    "    'Moped Driver': 'Other',\n",
    "    'Driver - Not Hit': 'Other',\n",
    "    'Wheelchair': 'Other',\n",
    "    'In-Line Skater': 'Other',\n",
    "    'Cyclist Passenger': 'Passenger',\n",
    "    'Trailer Owner': 'Vehicle Owner',\n",
    "    'Pedestrian - Not Hit': 'Other',\n",
    "    'Witness': 'Other',\n",
    "    'Moped Passenger': 'Passenger'\n",
    "    }\n",
    "\n",
    "df['INVTYPE'] = df['INVTYPE'].map(invtype_map)\n",
    "\n",
    "# Fill the missing values with Other\n",
    "df['INVTYPE'] = df['INVTYPE'].fillna('Other')\n",
    "\n",
    "# MANOEUVER\n",
    "# Going Ahead                            6265\n",
    "# Turning Left                           1786\n",
    "# Stopped                                 620\n",
    "# Turning Right                           476\n",
    "# Slowing or Stopping                     282\n",
    "# Changing Lanes                          216\n",
    "# Parked                                  183\n",
    "# Other                                   181\n",
    "# Reversing                               122\n",
    "# Unknown                                 122\n",
    "# Making U Turn                           106\n",
    "# Overtaking                               91\n",
    "# Pulling Away from Shoulder or Curb       40\n",
    "# Pulling Onto Shoulder or towardCurb      18\n",
    "# Merging                                  18\n",
    "# Disabled                                  4\n",
    "# Name: count, dtype: int64\n",
    "# Null Values: 7659\n",
    "\n",
    "# Too difficult to simplify and too much missing values, we will drop it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ROAD_CLASS', 'DISTRICT', 'LATITUDE', 'LONGITUDE', 'ACCLOC',\n",
       "       'TRAFFCTL', 'VISIBILITY', 'LIGHT', 'RDSFCOND', 'ACCLASS',\n",
       "       'INVTYPE', 'INVAGE', 'INJURY', 'INITDIR', 'DRIVACT', 'PEDESTRIAN',\n",
       "       'CYCLIST', 'AUTOMOBILE', 'MOTORCYCLE', 'TRUCK', 'TRSN_CITY_VEH',\n",
       "       'EMERG_VEH', 'PASSENGER', 'SPEEDING', 'AG_DRIV', 'REDLIGHT',\n",
       "       'ALCOHOL', 'DISABILITY', 'HOOD_158', 'HOOD_140'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROAD_CLASS\n",
      "Major Arterial    12951\n",
      "Minor Arterial     2840\n",
      "Collector           996\n",
      "Local               841\n",
      "Other               561\n",
      "Name: count, dtype: int64\n",
      "Null Values: 0\n",
      "DISTRICT\n",
      "Toronto and East York    6230\n",
      "Etobicoke York           4207\n",
      "Scarborough              4111\n",
      "North York               3637\n",
      "Toronto East York           4\n",
      "Name: count, dtype: int64\n",
      "Null Values: 0\n",
      "LATITUDE\n",
      "43.740245    48\n",
      "43.650845    35\n",
      "43.682345    34\n",
      "43.656345    30\n",
      "43.654945    29\n",
      "             ..\n",
      "43.615945     1\n",
      "43.632745     1\n",
      "43.682849     1\n",
      "43.749804     1\n",
      "43.661425     1\n",
      "Name: count, Length: 4498, dtype: int64\n",
      "Null Values: 0\n",
      "LONGITUDE\n",
      "-79.251190    36\n",
      "-79.386590    32\n",
      "-79.327990    30\n",
      "-79.383790    26\n",
      "-79.420090    25\n",
      "              ..\n",
      "-79.587390     1\n",
      "-79.349437     1\n",
      "-79.536365     1\n",
      "-79.610454     1\n",
      "-79.445216     1\n",
      "Name: count, Length: 4935, dtype: int64\n",
      "Null Values: 0\n",
      "LOCCOORD\n",
      "Intersection                           11963\n",
      "Mid-Block                               6110\n",
      "Mid-Block (Abnormal)                       8\n",
      "Exit Ramp Westbound                        5\n",
      "Exit Ramp Southbound                       3\n",
      "Park, Private Property, Public Lane        3\n",
      "Entrance Ramp Westbound                    2\n",
      "Name: count, dtype: int64\n",
      "Null Values: 95\n",
      "ACCLOC\n",
      "At Intersection     9889\n",
      "Other               5880\n",
      "Non Intersection    2420\n",
      "Name: count, dtype: int64\n",
      "Null Values: 0\n",
      "TRAFFCTL\n",
      "No Control        8788\n",
      "Traffic Signal    7635\n",
      "Stop Sign         1380\n",
      "Other              386\n",
      "Name: count, dtype: int64\n",
      "Null Values: 0\n",
      "VISIBILITY\n",
      "Clear    15714\n",
      "Rain      1879\n",
      "Snow       351\n",
      "Other      245\n",
      "Name: count, dtype: int64\n",
      "Null Values: 0\n",
      "LIGHT\n",
      "Daylight    10526\n",
      "Dark         6987\n",
      "Dusk          459\n",
      "Dawn          211\n",
      "Other           6\n",
      "Name: count, dtype: int64\n",
      "Null Values: 0\n",
      "RDSFCOND\n",
      "Dry      14594\n",
      "Wet       3021\n",
      "Snow       315\n",
      "Other      182\n",
      "Ice         77\n",
      "Name: count, dtype: int64\n",
      "Null Values: 0\n",
      "ACCLASS\n",
      "Non-Fatal Injury        15599\n",
      "Fatal                    2573\n",
      "Property Damage Only       17\n",
      "Name: count, dtype: int64\n",
      "Null Values: 0\n",
      "INVTYPE\n",
      "Driver           9317\n",
      "Pedestrian       3110\n",
      "Passenger        2809\n",
      "Vehicle Owner    1639\n",
      "Cyclist           784\n",
      "Other             530\n",
      "Name: count, dtype: int64\n",
      "Null Values: 0\n",
      "INVAGE\n",
      "20 to 40    6043\n",
      "40 to 60    4913\n",
      "unknown     2609\n",
      "60 to 80    2521\n",
      "0 to 20     1477\n",
      "over 80      626\n",
      "Name: count, dtype: int64\n",
      "Null Values: 0\n",
      "INJURY\n",
      "Major      6149\n",
      "Minor      1422\n",
      "Minimal    1123\n",
      "Fatal       931\n",
      "Name: count, dtype: int64\n",
      "Null Values: 8564\n",
      "INITDIR\n",
      "Unknown    5561\n",
      "East       3259\n",
      "West       3197\n",
      "South      3106\n",
      "North      3066\n",
      "Name: count, dtype: int64\n",
      "Null Values: 0\n",
      "DRIVACT\n",
      "Driving Properly                4221\n",
      "Failed to Yield Right of Way    1541\n",
      "Lost control                     975\n",
      "Improper Turn                    573\n",
      "Other                            504\n",
      "Disobeyed Traffic Control        475\n",
      "Following too Close              251\n",
      "Exceeding Speed Limit            246\n",
      "Speed too Fast For Condition     208\n",
      "Improper Lane Change             122\n",
      "Improper Passing                 112\n",
      "Wrong Way on One Way Road          9\n",
      "Speed too Slow                     4\n",
      "Name: count, dtype: int64\n",
      "Null Values: 8948\n",
      "PEDESTRIAN\n",
      "Yes    7349\n",
      "Name: count, dtype: int64\n",
      "Null Values: 10840\n",
      "CYCLIST\n",
      "Yes    1906\n",
      "Name: count, dtype: int64\n",
      "Null Values: 16283\n",
      "AUTOMOBILE\n",
      "Yes    16545\n",
      "Name: count, dtype: int64\n",
      "Null Values: 1644\n",
      "MOTORCYCLE\n",
      "Yes    1587\n",
      "Name: count, dtype: int64\n",
      "Null Values: 16602\n",
      "TRUCK\n",
      "Yes    1122\n",
      "Name: count, dtype: int64\n",
      "Null Values: 17067\n",
      "TRSN_CITY_VEH\n",
      "Yes    1110\n",
      "Name: count, dtype: int64\n",
      "Null Values: 17079\n",
      "EMERG_VEH\n",
      "Yes    43\n",
      "Name: count, dtype: int64\n",
      "Null Values: 18146\n",
      "PASSENGER\n",
      "Yes    6903\n",
      "Name: count, dtype: int64\n",
      "Null Values: 11286\n",
      "SPEEDING\n",
      "Yes    2575\n",
      "Name: count, dtype: int64\n",
      "Null Values: 15614\n",
      "AG_DRIV\n",
      "Yes    9460\n",
      "Name: count, dtype: int64\n",
      "Null Values: 8729\n",
      "REDLIGHT\n",
      "Yes    1520\n",
      "Name: count, dtype: int64\n",
      "Null Values: 16669\n",
      "ALCOHOL\n",
      "Yes    788\n",
      "Name: count, dtype: int64\n",
      "Null Values: 17401\n",
      "DISABILITY\n",
      "Yes    486\n",
      "Name: count, dtype: int64\n",
      "Null Values: 17703\n",
      "HOOD_158\n",
      "1      579\n",
      "170    375\n",
      "119    340\n",
      "70     339\n",
      "85     296\n",
      "      ... \n",
      "140     25\n",
      "173     25\n",
      "67      20\n",
      "29      18\n",
      "114     18\n",
      "Name: count, Length: 159, dtype: int64\n",
      "Null Values: 0\n",
      "HOOD_140\n",
      "77     703\n",
      "1      574\n",
      "76     443\n",
      "137    383\n",
      "70     341\n",
      "      ... \n",
      "29      29\n",
      "66      28\n",
      "140     25\n",
      "67      20\n",
      "114     18\n",
      "Name: count, Length: 141, dtype: int64\n",
      "Null Values: 0\n"
     ]
    }
   ],
   "source": [
    "for item in df.columns.values:\n",
    "    print(df[item].value_counts())\n",
    "    print('Null Values:', df[item].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns can be try to exclude or include\n",
    "try_columns = ['DIVISION', 'LOCCOORD', 'INJURY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LONGITUDE', 'LATITUDE', 'HOOD_158', 'HOOD_140', 'ACCLASS']\n"
     ]
    }
   ],
   "source": [
    "#Find remaining columns\n",
    "remaining_columns = list(set(df.columns.values) - set(meaningless_columns) - set(too_much_missing) - set(duplicate_columns) - set(fill_zero_columns) - set(fill_nan_columns) - set(categorical_columns) - set(try_columns))\n",
    "print(remaining_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HOOD_140     0\n",
       "ACCLASS      0\n",
       "LATITUDE     0\n",
       "LONGITUDE    0\n",
       "HOOD_158     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check remaining columns for missing values\n",
    "df[remaining_columns].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a copy of the dataframe\n",
    "df_copy = df.copy()\n",
    "\n",
    "#Drop meaningless columns\n",
    "df_copy = df_copy.drop(columns=meaningless_columns)\n",
    "#Drop too much missing columns\n",
    "df_copy = df_copy.drop(columns=too_much_missing)\n",
    "#Drop duplicate columns\n",
    "df_copy = df_copy.drop(columns=duplicate_columns)\n",
    "#Fill missing values with 'No'\n",
    "df_copy[fill_nan_columns] = df_copy[fill_nan_columns].fillna(value='No')\n",
    "#Fill missing values with 0\n",
    "df_copy[fill_zero_columns] = df_copy[fill_zero_columns].fillna(value=0)\n",
    "\n",
    "#drop y column\n",
    "df_copy = df_copy.drop(columns=['ACCLASS'])\n",
    "\n",
    "#Set y as target variable\n",
    "y = df['ACCLASS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_copy, y, test_size=0.8, random_state=58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3637, 34) (14552, 34) (3637,) (14552,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.replace({'Property Damage Only': 'Non-Fatal Injury'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACCLASS\n",
       "Non-Fatal Injury    15616\n",
       "Fatal                2573\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#tartget values are imbalanced, we will use SMOTE to balance the target values\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m over_sampling\n\u001b[0;32m      3\u001b[0m smote \u001b[38;5;241m=\u001b[39m over_sampling\u001b[38;5;241m.\u001b[39mSMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m58\u001b[39m)\n\u001b[0;32m      4\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m smote\u001b[38;5;241m.\u001b[39mfit_resample(X_train, y_train)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\imblearn\\__init__.py:52\u001b[0m\n\u001b[0;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     53\u001b[0m         combine,\n\u001b[0;32m     54\u001b[0m         ensemble,\n\u001b[0;32m     55\u001b[0m         exceptions,\n\u001b[0;32m     56\u001b[0m         metrics,\n\u001b[0;32m     57\u001b[0m         over_sampling,\n\u001b[0;32m     58\u001b[0m         pipeline,\n\u001b[0;32m     59\u001b[0m         tensorflow,\n\u001b[0;32m     60\u001b[0m         under_sampling,\n\u001b[0;32m     61\u001b[0m         utils,\n\u001b[0;32m     62\u001b[0m     )\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\imblearn\\combine\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\imblearn\\combine\\_smote_enn.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\imblearn\\base.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_sampling_strategy, check_target_type\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArraysTransformer\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSamplerMixin\u001b[39;00m(BaseEstimator, metaclass\u001b[38;5;241m=\u001b[39mABCMeta):\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\imblearn\\utils\\_param_validation.py:908\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_valid_param  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m    907\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m--> 908\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    909\u001b[0m     HasMethods,\n\u001b[0;32m    910\u001b[0m     Hidden,\n\u001b[0;32m    911\u001b[0m     Interval,\n\u001b[0;32m    912\u001b[0m     Options,\n\u001b[0;32m    913\u001b[0m     StrOptions,\n\u001b[0;32m    914\u001b[0m     _ArrayLikes,\n\u001b[0;32m    915\u001b[0m     _Booleans,\n\u001b[0;32m    916\u001b[0m     _Callables,\n\u001b[0;32m    917\u001b[0m     _CVObjects,\n\u001b[0;32m    918\u001b[0m     _InstancesOf,\n\u001b[0;32m    919\u001b[0m     _IterablesNotString,\n\u001b[0;32m    920\u001b[0m     _MissingValues,\n\u001b[0;32m    921\u001b[0m     _NoneConstraint,\n\u001b[0;32m    922\u001b[0m     _PandasNAConstraint,\n\u001b[0;32m    923\u001b[0m     _RandomStates,\n\u001b[0;32m    924\u001b[0m     _SparseMatrices,\n\u001b[0;32m    925\u001b[0m     _VerboseHelper,\n\u001b[0;32m    926\u001b[0m     make_constraint,\n\u001b[0;32m    927\u001b[0m     validate_params,\n\u001b[0;32m    928\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py)"
     ]
    }
   ],
   "source": [
    "#tartget values are imbalanced, we will use SMOTE to balance the target values\n",
    "from imblearn import over_sampling\n",
    "smote = over_sampling.SMOTE(random_state=58)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a pipeline to transform the data\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "#Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "#Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, remaining_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns)\n",
    "    ])\n",
    "\n",
    "#Define the model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "#Bundle preprocessing and modeling code in a pipeline\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', model)\n",
    "                     ])\n",
    "\n",
    "#Preprocessing of training data, fit model\n",
    "clf.fit(df_copy, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCLASS\n",
      "Non-Fatal Injury        15599\n",
      "Fatal                    2573\n",
      "Property Damage Only       17\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Mapping for target column\n",
    "print(df['ACCLASS'].value_counts())\n",
    "\n",
    "# Only Fatal and Non-Fatal from our prediction\n",
    "# 1 for Fatal, 0 for Non-Fatal\n",
    "data_map = {\n",
    "    'Fatal': 1, \n",
    "    'Non-Fatal Injury': 0, \n",
    "    'Property Damage Only': 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>INDEX_</th>\n",
       "      <th>ACCNUM</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>TIME</th>\n",
       "      <th>WARDNUM</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>FATAL_NO</th>\n",
       "      <th>ObjectId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.819400e+04</td>\n",
       "      <td>1.819400e+04</td>\n",
       "      <td>1.819400e+04</td>\n",
       "      <td>1.326400e+04</td>\n",
       "      <td>18194.000000</td>\n",
       "      <td>18194.000000</td>\n",
       "      <td>1.733200e+04</td>\n",
       "      <td>18194.000000</td>\n",
       "      <td>18194.000000</td>\n",
       "      <td>827.000000</td>\n",
       "      <td>18194.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-8.838345e+06</td>\n",
       "      <td>5.420748e+06</td>\n",
       "      <td>3.818870e+07</td>\n",
       "      <td>4.248444e+08</td>\n",
       "      <td>2012.934869</td>\n",
       "      <td>1362.615917</td>\n",
       "      <td>2.521028e+03</td>\n",
       "      <td>43.710459</td>\n",
       "      <td>-79.396201</td>\n",
       "      <td>29.073761</td>\n",
       "      <td>9097.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.162533e+04</td>\n",
       "      <td>8.682160e+03</td>\n",
       "      <td>3.726463e+07</td>\n",
       "      <td>1.065503e+09</td>\n",
       "      <td>4.754258</td>\n",
       "      <td>630.816048</td>\n",
       "      <td>1.844803e+05</td>\n",
       "      <td>0.056369</td>\n",
       "      <td>0.104432</td>\n",
       "      <td>17.803627</td>\n",
       "      <td>5252.299734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-8.865305e+06</td>\n",
       "      <td>5.402162e+06</td>\n",
       "      <td>3.363207e+06</td>\n",
       "      <td>2.530100e+04</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>43.589678</td>\n",
       "      <td>-79.638390</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.846591e+06</td>\n",
       "      <td>5.413242e+06</td>\n",
       "      <td>5.391370e+06</td>\n",
       "      <td>1.021229e+06</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>920.000000</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>43.661727</td>\n",
       "      <td>-79.470280</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4549.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-8.838448e+06</td>\n",
       "      <td>5.419556e+06</td>\n",
       "      <td>7.644612e+06</td>\n",
       "      <td>1.197308e+06</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>1450.000000</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>43.702745</td>\n",
       "      <td>-79.397132</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>9097.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-8.829671e+06</td>\n",
       "      <td>5.427813e+06</td>\n",
       "      <td>8.078261e+07</td>\n",
       "      <td>1.365020e+06</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>1850.000000</td>\n",
       "      <td>2.200000e+01</td>\n",
       "      <td>43.756345</td>\n",
       "      <td>-79.318286</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>13645.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-8.807929e+06</td>\n",
       "      <td>5.443099e+06</td>\n",
       "      <td>8.170606e+07</td>\n",
       "      <td>4.008024e+09</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2359.000000</td>\n",
       "      <td>1.716222e+07</td>\n",
       "      <td>43.855445</td>\n",
       "      <td>-79.122974</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>18194.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  X             Y        INDEX_        ACCNUM          YEAR  \\\n",
       "count  1.819400e+04  1.819400e+04  1.819400e+04  1.326400e+04  18194.000000   \n",
       "mean  -8.838345e+06  5.420748e+06  3.818870e+07  4.248444e+08   2012.934869   \n",
       "std    1.162533e+04  8.682160e+03  3.726463e+07  1.065503e+09      4.754258   \n",
       "min   -8.865305e+06  5.402162e+06  3.363207e+06  2.530100e+04   2006.000000   \n",
       "25%   -8.846591e+06  5.413242e+06  5.391370e+06  1.021229e+06   2009.000000   \n",
       "50%   -8.838448e+06  5.419556e+06  7.644612e+06  1.197308e+06   2012.000000   \n",
       "75%   -8.829671e+06  5.427813e+06  8.078261e+07  1.365020e+06   2017.000000   \n",
       "max   -8.807929e+06  5.443099e+06  8.170606e+07  4.008024e+09   2022.000000   \n",
       "\n",
       "               TIME       WARDNUM      LATITUDE     LONGITUDE    FATAL_NO  \\\n",
       "count  18194.000000  1.733200e+04  18194.000000  18194.000000  827.000000   \n",
       "mean    1362.615917  2.521028e+03     43.710459    -79.396201   29.073761   \n",
       "std      630.816048  1.844803e+05      0.056369      0.104432   17.803627   \n",
       "min        0.000000  1.000000e+00     43.589678    -79.638390    1.000000   \n",
       "25%      920.000000  7.000000e+00     43.661727    -79.470280   14.000000   \n",
       "50%     1450.000000  1.300000e+01     43.702745    -79.397132   28.000000   \n",
       "75%     1850.000000  2.200000e+01     43.756345    -79.318286   42.000000   \n",
       "max     2359.000000  1.716222e+07     43.855445    -79.122974   78.000000   \n",
       "\n",
       "           ObjectId  \n",
       "count  18194.000000  \n",
       "mean    9097.500000  \n",
       "std     5252.299734  \n",
       "min        1.000000  \n",
       "25%     4549.250000  \n",
       "50%     9097.500000  \n",
       "75%    13645.750000  \n",
       "max    18194.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
